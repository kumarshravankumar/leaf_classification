    Solving process of leaf classification problem
1.First I had taken input data and divide into training dataset and testing dataset
and also taken corresponding images that is 
train.csv
test.csv
images.zip
Whole code is written in python

2.First I load several helpful packages to load in 
import numpy as np     # for linear algebra
import pandas as pd     # for data processing, CSV file (e.g. pd.read_csv)
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit

3.I use Logistic Regression and random forest classifier  and 
A large amount of the data loading code is based on najeebkhan's kernel

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
train = pd.read_csv('../input/train.csv') # Read the data to train the model

4.Loads the pre-extracted features for the training data
    and returns a tuple of the image ids, the data, and the labels
# Read data from the CSV file
 # Since the labels are textual, so we encode them categorically
# standardize the data by setting the mean to 0 and std to 1

5.Loads the pre-extracted features for the test data
    and returns a tuple of the image ids, the data
# standardize the data by setting the mean to 0 and std to 1

6. Resize the image to so the maximum side is of size max_dim
    Returns a new image of the right size
   # Get the axis with the larger dimension
   # Scale both axes so the image's largest dimension is max_dim

7.Takes as input an array of image ids and loads the images as numpy
    arrays with the images resized so the longest side is max-dim length.
    If center is True, then will place the image in the center of
    the output array, otherwise it will be placed at the top-left corner.
       # Initialize the output array
     # Turn the image into an array
     # Get the corners of the bounding box for the image
     # Insert into image matrix
     # Scale the array values so they are between 0 and 1
8.Loads the pre-extracted feature and image training data and
    splits them into training and cross-validation.
    Returns one tuple for the training data and one for the validation
    data. Each tuple is in the order pre-extracted features, images,
    and labels.
    # Load the pre-extracted features
    # Load the image data
    # Split them into validation and cross-validation
9.Loads the pre-extracted feature and image test data.
    Returns a tuple in the order ids, pre-extracted features,
    and images.
    # Load the pre-extracted features
    # Load the image data
print('Loading the training data...')
print('Training data loaded!')

10. for python 2.x. Keeps under lock only the mechanism which advances
     the indexing of each batch
       # We changed index_array to self.index_array
      # The transformation of images is not under thread lock so it can be done in parallel

print('Creating Data Augmenter...')
print('Finished making data augmenter...')
11.Creating the model
A generator to train our keras neural network. It
    takes the image augmenter generator and the array
    of the pre-extracted features.
    It yields a minibatch and will run indefinitely
            # Get the image batch and labels
            # This is where that change to the source code we
            # made will come in handy. We can now access the indicies
            # of the images that imgen gave us.
           # autosave best Model
print('Training model...')
print('Loading the best model...')
print('Best Model loaded!')

# Get the names of the column headers
# Converting the test predictions in a dataframe as depicted by sample submission
print('Creating and writing submission...')
fp = open('submit.csv', 'w')
fp.write(yPred.to_csv())
print('Finished writing submission')
# Display the submission
yPred.tail()




